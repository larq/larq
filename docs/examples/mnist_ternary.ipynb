{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSPCom-KmApV"
   },
   "source": [
    "# Ternarized Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLGkt5qiyz4E"
   },
   "source": [
    "This tutorial demonstrates training a simple Ternarized Convolutional Neural Network to classify MNIST digits. It uses the same model architecture as the Binarized example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m7KBpffWzlxH"
   },
   "source": [
    "### Import TensorFlow and Larq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iAve6DCL4JH4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import larq as lq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRFxccghyMVo"
   },
   "source": [
    "### Download and prepare the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWoEqyMuXFF4"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# Normalize pixel values to be between -1 and 1\n",
    "train_images, test_images = train_images / 127.5 - 1., test_images / 127.5 - 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oewp-wYg31t9"
   },
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9YmGQBQPrdn"
   },
   "outputs": [],
   "source": [
    "kwargs = dict(input_quantizer=lq.quantizers.SteTern(threshold_value=0.05), kernel_quantizer=lq.quantizers.SteTern(threshold_value=0.05), kernel_constraint=\"weight_clip\")\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(lq.layers.QuantConv2D(32, (3, 3), kernel_quantizer=lq.quantizers.SteTern(threshold_value=0.05), kernel_constraint=\"weight_clip\", use_bias=False, input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(lq.layers.QuantDense(64, use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvDVFkg-2DPm"
   },
   "source": [
    "Here's the complete architecture of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-C4XBg4UTJy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quant_conv2d (QuantConv2D)   (None, 26, 26, 32)        288       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 13, 13, 32)        96        \n",
      "_________________________________________________________________\n",
      "quant_conv2d_1 (QuantConv2D) (None, 11, 11, 64)        18432     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 5, 64)          192       \n",
      "_________________________________________________________________\n",
      "quant_conv2d_2 (QuantConv2D) (None, 3, 3, 64)          36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 3, 3, 64)          192       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "quant_dense (QuantDense)     (None, 64)                36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "quant_dense_1 (QuantDense)   (None, 10)                640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 93,790\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 468\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P3odqfHP4M67"
   },
   "source": [
    "### Compile and train the model\n",
    "\n",
    "Note: This may take a few minutes depending on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdDzI75PUXrG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.5812 - acc: 0.9297\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.4554 - acc: 0.9675\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.4343 - acc: 0.9746\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.4207 - acc: 0.9783\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.4187 - acc: 0.9795\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.4179 - acc: 0.9811\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.4130 - acc: 0.9822\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.4117 - acc: 0.9827\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.4094 - acc: 0.9837\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.4077 - acc: 0.9847\n",
      "10000/10000 [==============================] - 1s 53us/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, batch_size=50, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKgyC5K_4O0d"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0LvwaKhtUdOo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 98.90 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy {test_acc * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cfJ8AR03gT5"
   },
   "source": [
    "As you can see, our simple binarized CNN has achieved a test accuracy of over 97.5 %. Not bad for a few lines of code!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "intro_to_cnns.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nteract": {
   "version": "0.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
