{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BinaryNet on CIFAR10 (Advanced)\n",
        "\n",
        "<a href=\"https://mybinder.org/v2/gh/larq/larq/master?filepath=docs%2Fexamples%2Fbinarynet_advanced_cifar10.ipynb\"><button data-md-color-primary=\"blue\">Run on Binder</button></a> <a href=\"https://github.com/larq/larq/blob/master/docs/examples/binarynet_advanced_cifar10.ipynb\"><button data-md-color-primary=\"blue\">View on GitHub</button></a>\n",
        "\n",
        "In this example we demonstrate how to use Larq to build and train BinaryNet on the CIFAR10 dataset to achieve a validation accuracy of around 90% using a heavy lifting GPU like a Nvidia V100.\n",
        "On a Nvidia V100 it takes approximately 250 minutes to train. Compared to the original papers, [BinaryConnect: Training Deep Neural Networks with binary weights during propagations](https://arxiv.org/abs/1511.00363), and [Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1](http://arxiv.org/abs/1602.02830), we do not implement image whitening, but we use image augmentation, and a stepped learning rate scheduler."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import larq as lq\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import CIFAR10 Dataset\n",
        "\n",
        "Here we download the CIFAR10 dataset:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = tf.keras.datasets.cifar10.load_data()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we define our image augmentation technqiues, and create the dataset:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_and_flip(image, labels, training):\n",
        "    image = tf.cast(image, tf.float32) / (255./2.) - 1.\n",
        "    if training:\n",
        "        image = tf.image.resize_image_with_crop_or_pad(image, 40, 40)\n",
        "        image = tf.random_crop(image, [32, 32, 3])\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "    return image, labels"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(data, batch_size, training):\n",
        "    images, labels = data\n",
        "    labels = tf.one_hot(np.squeeze(labels), 10)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    dataset = dataset.repeat()\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000)\n",
        "    dataset = dataset.map(lambda x, y: resize_and_flip(x, y, training))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "\n",
        "train_dataset = create_dataset(train_data, batch_size, True)\n",
        "test_dataset = create_dataset(test_data, batch_size, False)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build BinaryNet\n",
        "\n",
        "Here we build the binarynet model layer by layer using a keras sequential model:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# All quantized layers except the first will use the same options\n",
        "kwargs = dict(input_quantizer=\"ste_sign\",\n",
        "              kernel_quantizer=\"ste_sign\",\n",
        "              kernel_constraint=\"weight_clip\",\n",
        "              use_bias=False)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # In the first layer we only quantize the weights and not the input\n",
        "    lq.layers.QuantConv2D(128, 3,\n",
        "                          kernel_quantizer=\"ste_sign\",\n",
        "                          kernel_constraint=\"weight_clip\",\n",
        "                          use_bias=False,\n",
        "                          input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D(128, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D(256, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D(256, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D(512, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D(512, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    lq.layers.QuantDense(1024, **kwargs),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantDense(1024, **kwargs),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantDense(10, **kwargs),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "    tf.keras.layers.Activation(\"softmax\")\n",
        "])"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Larq allows you to print a summary of the model that includes bit-precision information:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "lq.models.summary(model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+sequential_1 stats-------------------------------------------------------------------+\n",
            "| Layer                   Input prec.            Outputs   # 1-bit  # 32-bit   Memory |\n",
            "|                               (bit)                                            (kB) |\n",
            "+-------------------------------------------------------------------------------------+\n",
            "| quant_conv2d_6                    -  (-1, 30, 30, 128)      3456         0     0.42 |\n",
            "| batch_normalization_9             -  (-1, 30, 30, 128)         0       384     1.50 |\n",
            "| quant_conv2d_7                    1  (-1, 30, 30, 128)    147456         0    18.00 |\n",
            "| max_pooling2d_3                   -  (-1, 15, 15, 128)         0         0     0.00 |\n",
            "| batch_normalization_10            -  (-1, 15, 15, 128)         0       384     1.50 |\n",
            "| quant_conv2d_8                    1  (-1, 15, 15, 256)    294912         0    36.00 |\n",
            "| batch_normalization_11            -  (-1, 15, 15, 256)         0       768     3.00 |\n",
            "| quant_conv2d_9                    1  (-1, 15, 15, 256)    589824         0    72.00 |\n",
            "| max_pooling2d_4                   -    (-1, 7, 7, 256)         0         0     0.00 |\n",
            "| batch_normalization_12            -    (-1, 7, 7, 256)         0       768     3.00 |\n",
            "| quant_conv2d_10                   1    (-1, 7, 7, 512)   1179648         0   144.00 |\n",
            "| batch_normalization_13            -    (-1, 7, 7, 512)         0      1536     6.00 |\n",
            "| quant_conv2d_11                   1    (-1, 7, 7, 512)   2359296         0   288.00 |\n",
            "| max_pooling2d_5                   -    (-1, 3, 3, 512)         0         0     0.00 |\n",
            "| batch_normalization_14            -    (-1, 3, 3, 512)         0      1536     6.00 |\n",
            "| flatten_1                         -         (-1, 4608)         0         0     0.00 |\n",
            "| quant_dense_3                     1         (-1, 1024)   4718592         0   576.00 |\n",
            "| batch_normalization_15            -         (-1, 1024)         0      3072    12.00 |\n",
            "| quant_dense_4                     1         (-1, 1024)   1048576         0   128.00 |\n",
            "| batch_normalization_16            -         (-1, 1024)         0      3072    12.00 |\n",
            "| quant_dense_5                     1           (-1, 10)     10240         0     1.25 |\n",
            "| batch_normalization_17            -           (-1, 10)         0        30     0.12 |\n",
            "| activation_1                      -           (-1, 10)         0         0     0.00 |\n",
            "+-------------------------------------------------------------------------------------+\n",
            "| Total                                                   10352000     11550  1308.79 |\n",
            "+-------------------------------------------------------------------------------------+\n",
            "+sequential_1 summary-------------+\n",
            "| Total params           10363550 |\n",
            "| Trainable params       10355850 |\n",
            "| Non-trainable params   7700     |\n",
            "| Float-32 Equivalent    39.53 MB |\n",
            "| Compression of Memory  30.93    |\n",
            "+---------------------------------+\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training\n",
        "\n",
        "We compile and train the model as you are used to in Keras:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "initial_lr = 1e-3\n",
        "var_decay = 1e-5\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=initial_lr, decay=var_decay)\n",
        "model.compile(\n",
        "    optimizer=lq.optimizers.XavierLearningRateScaling(optimizer, model),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "    return initial_lr * 0.1 ** (epoch // 100)\n",
        "\n",
        "trained_model = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=500,\n",
        "    steps_per_epoch=train_data[1].shape[0] // batch_size,\n",
        "    validation_data=test_dataset,\n",
        "    validation_steps=test_data[1].shape[0] // batch_size,\n",
        "    verbose=1,\n",
        "    callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_schedule)]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "outputExpanded": true,
        "scrolled": true
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
