{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Larq Zoo Tutorial\n",
        "\n",
        "<a href=\"https://mybinder.org/v2/gh/larq/larq/master?filepath=docs%2Fmodels%2Fexamples.ipynb\"><button data-md-color-primary=\"larq\">Run on Binder</button></a> <a href=\"https://github.com/larq/larq/blob/master/docs/models/examples.ipynb\"><button data-md-color-primary=\"larq\">View on GitHub</button></a>\n",
        "\n",
        "This tutorial demonstrates how to load pretrained models from Larq Zoo. These models can be used for prediction, feature extraction, and fine-tuning."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import larq_zoo as lqz\n",
        "from urllib.request import urlopen"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and prepare a sample image\n",
        "\n",
        "In the following we will use a sample image from the [ImageNet](http://image-net.org/) dataset:\n",
        "<img src=\"https://raw.githubusercontent.com/larq/zoo/master/tests/fixtures/elephant.jpg\" width=\"50%\">"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"https://raw.githubusercontent.com/larq/zoo/master/tests/fixtures/elephant.jpg\"\n",
        "\n",
        "with urlopen(img_path) as f:\n",
        "    img = tf.keras.preprocessing.image.load_img(f, target_size=(224, 224))\n",
        "\n",
        "x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "x = lqz.preprocess_input(x)\n",
        "x = np.expand_dims(x, axis=0)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify ImageNet classes with Bi-Real Net\n",
        "\n",
        "We will first load the Bi-Real Net architecture with pretrained weights and predict the image class."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = lqz.BiRealNet(weights=\"imagenet\")\n",
        "preds = model.predict(x)\n",
        "lqz.decode_predictions(preds, top=5)[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": [
              "[('n02504458', 'African_elephant', 0.7529364),\n",
              " ('n01871265', 'tusker', 0.22607337),\n",
              " ('n02504013', 'Indian_elephant', 0.017037684),\n",
              " ('n02410509', 'bison', 0.0016636014),\n",
              " ('n02412080', 'ram', 0.0014974006)]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract features with Bi-Real Net\n",
        "\n",
        "Larq Zoo models can also be used to extract features that can be used as input to a second model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = lqz.BiRealNet(weights=\"imagenet\", include_top=False)\n",
        "features = model.predict(x)\n",
        "print(\"Feature shape:\", features.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shape: (1, 7, 7, 512)\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract features from an arbitrary intermediate layer\n",
        "\n",
        "Features can also be extracted from arbitrary intermediate layer with just a few lines of code."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "avg_pool_layer = model.get_layer(\"average_pooling2d_2\")\n",
        "avg_pool_model = tf.keras.models.Model(\n",
        "    inputs=model.input, outputs=avg_pool_layer.output)\n",
        "\n",
        "avg_pool_features = avg_pool_model.predict(x)\n",
        "print(\"average_pooling2d_2 feature shape:\", avg_pool_features.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_pooling2d_2 feature shape: (1, 7, 7, 256)\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Bi-Real Net over a custom input Tensor\n",
        "\n",
        "The model can also be used with an input Tensor that might also be the output a different Keras model or layer."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = tf.keras.layers.Input(shape=(224, 224, 3))\n",
        "\n",
        "model = lqz.BiRealNet(input_tensor=input_tensor, weights=\"imagenet\")"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Bi-Real Net with TensorFlow Datasets\n",
        "\n",
        "To re-run the evaluation on the entire [ImageNet](http://image-net.org/) validation dataset [Tensorflow Datasets](https://www.tensorflow.org/datasets/) can be used.\n",
        "\n",
        "Note that running this example will download the entire dataset and might take a very long time to complete."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data):\n",
        "    img = lqz.preprocess_input(data[\"image\"])\n",
        "    label = tf.one_hot(data[\"label\"], 1000)\n",
        "    return img, label \n",
        "\n",
        "dataset = (\n",
        "    tfds.load(\"imagenet2012:5.0.0\", split=tfds.Split.VALIDATION)\n",
        "    .map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    .batch(128)\n",
        "    .prefetch(1)\n",
        ")\n",
        "\n",
        "model = lqz.BiRealNet()\n",
        "model.compile(\n",
        "    optimizer=\"sgd\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"categorical_accuracy\", \"top_k_categorical_accuracy\"],\n",
        ")\n",
        "\n",
        "model.evaluate(dataset)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}